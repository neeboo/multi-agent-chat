import { generateText } from "@/lib/llm"
import { openai } from "@/lib/llm"
import { deepseek } from "@ai-sdk/deepseek"

export interface AgentMessage {
  id: string
  role: "human" | "pm" | "engineer" | "qa"
  content: string
  timestamp: Date
}

export interface TaskContext {
  id: string
  originalRequest: string
  messages: AgentMessage[]
  status: "processing" | "completed" | "failed"
}

class MultiAgentSystem {
  private generateId() {
    return Math.random().toString(36).substr(2, 9)
  }

  async processTask(userRequest: string): Promise<TaskContext> {
    const taskId = this.generateId()
    const context: TaskContext = {
      id: taskId,
      originalRequest: userRequest,
      messages: [],
      status: "processing",
    }

    try {
      // ç”¨æˆ·è¯·æ±‚
      context.messages.push({
        id: this.generateId(),
        role: "human",
        content: userRequest,
        timestamp: new Date(),
      })

      // PM åˆ†æ
      const pmResponse = await this.callPM(userRequest)
      context.messages.push({
        id: this.generateId(),
        role: "pm",
        content: pmResponse,
        timestamp: new Date(),
      })

      // å·¥ç¨‹å¸ˆå®ç°
      const engineerResponse = await this.callEngineer(pmResponse, userRequest)
      context.messages.push({
        id: this.generateId(),
        role: "engineer",
        content: engineerResponse,
        timestamp: new Date(),
      })

      // QA å®¡æŸ¥
      const qaResponse = await this.callQA(engineerResponse, userRequest)
      context.messages.push({
        id: this.generateId(),
        role: "qa",
        content: qaResponse,
        timestamp: new Date(),
      })

      context.status = "completed"
    } catch (error) {
      context.status = "failed"
      context.messages.push({
        id: this.generateId(),
        role: "pm",
        content: `ç³»ç»Ÿé”™è¯¯: ${error instanceof Error ? error.message : "æœªçŸ¥é”™è¯¯"}`,
        timestamp: new Date(),
      })
    }

    return context
  }

  /* ---------- private helpers ---------- */

  private async callPM(request: string): Promise<string> {
    try {
      const result = await generateText({
        model: openai("gpt-4o-mini"),
        system: `ä½ æ˜¯ä¸€ä¸ªèµ„æ·±é¡¹ç›®ç»ç†ã€‚åˆ†æç”¨æˆ·éœ€æ±‚ï¼Œåˆ¶å®šæŠ€æœ¯æ–¹æ¡ˆã€‚
è¯·æŒ‰ä»¥ä¸‹æ ¼å¼å›å¤ï¼š
## ğŸ“‹ éœ€æ±‚åˆ†æ
## ğŸ¯ æ ¸å¿ƒåŠŸèƒ½
## ğŸ› ï¸ æŠ€æœ¯æ–¹æ¡ˆ
## ğŸ“ å¼€å‘æŒ‡å¯¼`,
        prompt: `ç”¨æˆ·éœ€æ±‚ï¼š${request}`,
      })
      return result.text
    } catch (error) {
      return `PMåˆ†æå¤±è´¥ï¼Œç®€è¦è¾“å‡ºï¼š${request}`
    }
  }

  private async callEngineer(pmAnalysis: string, originalRequest: string): Promise<string> {
    try {
      const result = await generateText({
        model: openai("gpt-4o-mini"),
        system: `ä½ æ˜¯ä¸€ä¸ªèµ„æ·±å…¨æ ˆå·¥ç¨‹å¸ˆã€‚æ ¹æ®PMåˆ†æå®ç°å…·ä½“ä»£ç ã€‚`,
        prompt: `é¡¹ç›®ç»ç†åˆ†æï¼š${pmAnalysis}

åŸå§‹éœ€æ±‚ï¼š${originalRequest}

è¯·æä¾›å®Œæ•´çš„ä»£ç å®ç°ã€‚`,
      })
      return result.text
    } catch {
      return "ä»£ç å®ç°å¤±è´¥ï¼Œè¯·æ£€æŸ¥ API é…ç½®"
    }
  }

  private async callQA(engineerCode: string, originalRequest: string): Promise<string> {
    try {
      const result = await generateText({
        model: deepseek("deepseek-chat"),
        system: `ä½ æ˜¯QAå·¥ç¨‹å¸ˆã€‚å®¡æŸ¥ä»£ç è´¨é‡å¹¶æå‡ºæµ‹è¯•å»ºè®®ã€‚`,
        prompt: `å·¥ç¨‹å¸ˆå®ç°ï¼š${engineerCode}

åŸå§‹éœ€æ±‚ï¼š${originalRequest}

è¯·è¾“å‡ºè¯¦ç»†çš„å®¡æŸ¥æŠ¥å‘Šã€‚`,
      })
      return result.text
    } catch {
      return "QAå®¡æŸ¥å¤±è´¥ï¼Œè¯·æ‰‹åŠ¨æ£€æŸ¥ä»£ç è´¨é‡"
    }
  }
}

/* ---------- named export expected by build ---------- */
export const multiAgentSystem = new MultiAgentSystem()
